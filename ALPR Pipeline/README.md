# Automated License Plate Recognition (ALPR) Pipeline

## Overview

This project provides a complete, multi-stage pipeline for automated license plate recognition. It is composed of several independent, continuous services that work in concert to process images, detect and read license plates, and match them against a database. The system is designed for high-throughput, robust, and continuous operation, making it suitable for real-time monitoring scenarios.

The pipeline is modular, meaning each stage is a separate, long-running process. This design allows for scalability and easy maintenance, as individual components can be updated or restarted without affecting the entire system.

## Pipeline Architecture

The pipeline consists of four main services that run concurrently, passing data from one stage to the next through a shared file system. An additional script is used for offline, post-processing analysis after a batch of images has been processed.


The data flows through the following stages:

1.  **LPD (License Plate Detection)** `(lpd_service.py)`
    * **Input**: A directory containing raw vehicle images (e.g., `.jpg`, `.png`).
    * **Action**: This service uses a YOLO detection model to scan each image and identify the coordinates of any license plates present.
    * **Output**: For each detected plate, a new, cropped image file (`.png`) is saved to a designated output directory. The filenames are structured to link back to the source image (e.g., `source_image_lp1.png`).

2.  **LPQA (License Plate Quality Assessment)** `(lpqa_service.py)`
    * **Input**: The directory of cropped license plate images generated by the LPD service.
    * **Action**: This crucial filtering step uses a YOLO classification model to assess the quality of each cropped image. It checks for factors like excessive blur, extreme angles, or poor lighting that would likely lead to an incorrect OCR reading.
    * **Output**: The service does not move files. Instead, it creates symbolic links to the original crops, sorting them into `accepted` and `rejected` subdirectories. This is an efficient way to categorize results without data duplication.

3.  **LPR (License Plate Recognition)** `(lpr_service.py)`
    * **Input**: The `accepted` directory containing high-quality crops from the LPQA service.
    * **Action**: Performs Optical Character Recognition (OCR) on the plate images using a highly accurate ParSeq model.
    * **Output**: A separate `.txt` file is created for each processed image. Each file contains the recognized license plate character string.

4.  **LPDBM (License Plate Database Matching)** `(lpdbm_service.py)`
    * **Input**: The directory of OCR `.txt` results from the LPR service.
    * **Action**: Reads the recognized plate string from each text file and performs a high-speed lookup against a pre-built SQLite database to find a matching ground truth record.
    * **Output**: A single, consolidated log file (e.g., `matches.log`) containing one line per detection. Each line records the filename, the OCR result, and the corresponding record retrieved from the database (or 'UNKNOWN' if no match is found).

5.  **Analysis** `(analysis.py)`
    * **Input**: The final, consolidated `matches.log` file from the LPDBM service.
    * **Action**: This script is run after the main pipeline has finished processing. It groups all results from the same source image, compares the best OCR text to the ground truth, and categorizes the outcome based on the number of matching characters.
    * **Output**: Multiple `.txt` files, one for each category of result (e.g., `7.txt` for perfect 7-character matches, `tie-6.txt` for ties with 6 matching characters, `unknown.txt` for plates not in the database).

## Core Service Architecture

All continuous services (`lpd`, `lpqa`, `lpr`, `lpdbm`) share a common, robust architecture designed for stability and performance:

* **Stateful Initialization**: On startup, each service scans its output directory to identify and skip already processed files. This allows the service to be stopped and resumed without redundant processing.
* **Continuous File Monitoring**: The `watchdog` library is used to monitor the input directory for new files in a non-blocking background thread. This ensures new data is detected immediately.
* **Multithreaded Processing**: A dedicated worker thread pulls file paths from a thread-safe queue. This decouples file detection from the computationally intensive model inference, preventing bottlenecks.
* **Efficient Batching**: The worker thread processes files in batches to maximize the throughput of the AI models. A configurable timeout ensures that even a slow stream of single files is processed in a timely manner.
* **Graceful Shutdown**: The services are designed to perform a graceful shutdown when a `KeyboardInterrupt` (`Ctrl+C`) is detected. They will finish processing any files in the current batch before exiting, preventing data loss.

## Developer Notes: Core Logic

This section details the internal logic of the more complex services for developers who may need to maintain or extend the pipeline.

### `lpd`, `lpqa`, and `lpr` Services
These three services follow a similar and straightforward logic:
1.  A watchdog monitors an input directory for new image files.
2.  Valid image paths are placed into a thread-safe queue.
3.  A separate worker thread pulls paths from the queue, collects them into a batch, and feeds the batch of images into the respective AI model for inference.
4.  The results are saved to the output directory. A key detail for `lpqa_service.py` is its use of symbolic links for categorization, which avoids data duplication and is highly efficient.

### `lpdbm_service.py`: High-Performance Database Matching
This service is optimized to avoid a common performance bottleneck: querying a database inside a loop. Instead of one query per file, it uses a highly efficient batch-query mechanism.
1.  **Batch Collection**: The service collects a large batch of incoming OCR `.txt` files from the queue (e.g., 1024 files).
2.  **Single, Consolidated Query**: It extracts the base filenames required for lookup and constructs a **single** SQL query to fetch all corresponding records at once using the `WHERE filename IN (...)` clause. This minimizes database communication overhead.
3.  **In-Memory Caching**: The results of this single query are loaded into a Python dictionary, creating a temporary, in-memory cache of the records for the current batch.
4.  **Fast Mapping and Writing**: The service then iterates through the files in its batch. For each file, it performs an extremely fast lookup in the in-memory dictionary and writes the combined result (filename, OCR text, database record) to the final `matches.log` file.

### `analysis.py`: Group-by-Change Logic
This service's logic is designed to group related entries (multiple plate detections from the same original image) without needing to load the entire log file into memory.
1.  **Assumption of Sorted Data**: The core logic relies on the assumption that the input `matches.log` file is naturally sorted by the base image name, as the upstream services process files in batches.
2.  **Stateful Grouping**: The script reads the log file line by line. It keeps a temporary list called `current_group` and adds each line's data to it.
3.  **Detecting the Break**: It continuously compares the base filename of the current line to the base filename of the previous line. As long as they are the same (e.g., `image001_lp1`, `image001_lp2`), it keeps adding to the group. When the base filename changes (e.g., to `image002_lp1`), it signifies that the previous group is complete.
4.  **Group Analysis**: Once a group is complete, the script processes it:
    * It calculates a character-match score for every entry in the group against the database record.
    * It identifies the entry (or entries) with the highest score.
    * It writes the best result to an output file named after the score (e.g., `7.txt`). If there is a tie for the best score, it writes all tied entries to a `tie-N.txt` file.
5.  **Reset and Continue**: After processing, the `current_group` is cleared, and the new line begins the next group. This allows the service to handle massive log files with a very small memory footprint.

## Getting Started

### Prerequisites

1.  **Python Environment**: It is recommended to use Python 3.8 or newer.

2.  **Python Libraries**: Install all required libraries using pip.
    ```bash
    pip install torch ultralytics opencv-python numpy watchdog Pillow
    ```

3.  **AI Models & Dependencies**: You must provide your own pre-trained models. The models used in this project are detailed below.
    * **LPD Model**: A YOLO detection model trained on several public ALPR datasets, including [RodoSol-ALPR](https://github.com/raysonlaroca/rodosol-alpr-dataset), UFOP, and SSIG-Plates.
    * **LPQA Model**: A YOLO classification model based on the methodology from the ["LPLC: A Dataset for License Plate Legibility Classification" paper](https://arxiv.org/abs/2508.18425) (available on arXiv).
    * **LPR Model**: A ParSeq (`parseq-tiny`) checkpoint trained on the [UFPR-VeSV-Dataset](https://github.com/Lima001/UFPR-VeSV-Dataset).
        * **Important**: The `lpr_service.py` script depends on the `strhub` source code for loading the ParSeq model. You must clone the official repository from `https://github.com/baudm/parseq` and ensure the `strhub` directory is present in the root of this project.

4.  **Database of Official Records (Private Data)**: This pipeline was designed to work with an official database of records from governmental institutions. The **database file itself is sensitive and must be kept private**.
    * **Shareable Service Code**: The `lpdbm_service.py` script, which connects to and queries the database, **contains no sensitive data** and is safe to share as part of the pipeline. It is merely a tool that requires a separate, private database file to function.
    * **Non-Shareable Components**: Due to data sensitivity, the database file and any utility scripts used to create or view it (e.g., `db_creator.py`, `db_view.py`) are not publicly available.
    * **User Responsibility**: To use the `LPDBM` service, you must provide your own private SQLite database with a compatible schema.

### Setup Instructions

1.  **Create Directory Structure**: Before running the services, create the necessary directories. This structure separates data, models, and outputs for clarity.
    ```bash
    mkdir -p alpr_pipeline/data/raw_images
    mkdir -p alpr_pipeline/models
    mkdir -p alpr_pipeline/output/1_lpd_crops
    mkdir -p alpr_pipeline/output/2_lpqa_sorted/accepted
    mkdir -p alpr_pipeline/output/2_lpqa_sorted/rejected
    mkdir -p alpr_pipeline/output/3_lpr_ocr
    mkdir -p alpr_pipeline/output/4_lpdbm_matches
    mkdir -p alpr_pipeline/output/5_analysis_results
    ```
    * Place your raw images in `alpr_pipeline/data/raw_images`.
    * Place your AI models in `alpr_pipeline/models`.
    * Place your private SQLite database in `alpr_pipeline/data`.

2.  **Prepare the Database**: The `LPDBM` service requires a SQLite database named `plates.db` located in the `alpr_pipeline/data/` directory. This database must contain a table named `records` with at least two columns: `filename` (TEXT, PRIMARY KEY) and `pmpr` (TEXT).
    * **Crucial**: The `filename` column must store the **base filename** of the original source image (e.g., `image001.jpg`, `photo_of_car.png`). It should **not** contain the `_lp_N` suffix that is added to the cropped plate images.

## Important Considerations and Implicit Assumptions

This section highlights critical operational details and assumptions in the code that developers must be aware of to prevent unexpected behavior.

* **Hardcoded Source Image Extension in `lpdbm_service.py`**:
    * **Issue**: The database matching service (`lpdbm_service.py`) assumes that all original source images have a `.jpg` extension. The code that reconstructs the base filename for a database lookup has this extension hardcoded.
    * **Impact**: If your source images are in a different format (e.g., `.png`, `.jpeg`, `.bmp`), the database lookup will fail for every image, and all results will be incorrectly classified as 'UNKNOWN'.
    * **Solution**: If you use a different image format, you must modify the `_batch_worker` function in `lpdbm_service.py` to use the correct extension.

* **Filesystem Requirement for Symbolic Links in `lpqa_service.py`**:
    * **Issue**: The quality assessment service (`lpqa_service.py`) uses symbolic links (`symlinks`) to sort images into `accepted` and `rejected` categories without duplicating files.
    * **Impact**: This feature requires a filesystem that supports symbolic links (e.g., ext4 on Linux, NTFS on Windows, APFS on macOS). It may fail on older or simpler filesystems like FAT32.
    * **Solution**: Ensure you run the pipeline on a modern operating system with a compatible filesystem.

* **Data Sorting Assumption in `analysis.py`**:
    * **Issue**: The core logic of the `analysis.py` script relies on its input file (`matches.log`) being naturally sorted by the original image's base name.
    * **Impact**: While the `lpdbm_service.py` naturally produces a sorted log due to its batching mechanism, any external process that modifies or reorders this log file could break the analysis script's grouping logic, leading to incorrect results.
    * **Solution**: Do not manually edit or re-sort the `matches.log` file before feeding it into the analysis script.

* **Resource Management**:
    * **Issue**: The LPD, LPQA, and LPR services load large AI models into memory.
    * **Impact**: Running all services simultaneously can be resource-intensive, particularly on GPU memory.
    * **Solution**: It is highly recommended to run these services on a machine with a dedicated NVIDIA GPU and sufficient VRAM. If performance is slow or you encounter memory errors, consider reducing the `--batch_size` for the most demanding services (`lpd_service.py` and `lpr_service.py`).

## Running the Pipeline

Each service must run in its own process. Open a separate terminal for each of the following commands and launch them in the specified order to ensure the data flows correctly.

**Terminal 1: Start the LPD Service**
*This service watches for raw images and produces cropped plates.*
```bash
python lpd_service.py \
  --input_dir "alpr_pipeline/data/raw_images" \
  --output_dir "alpr_pipeline/output/1_lpd_crops" \
  --model_path "alpr_pipeline/models/lpd_model.pt" \
  --crop
```

**Terminal 2: Start the LPQA Service**
*This service watches for new crops and sorts them by quality.*
```bash
python lpqa_service.py \
  --input_dir "alpr_pipeline/output/1_lpd_crops" \
  --output_dir "alpr_pipeline/output/2_lpqa_sorted" \
  --model_path "alpr_pipeline/models/lpqa_model.pt"
```

**Terminal 3: Start the LPR Service**
*This service watches for accepted-quality crops and performs OCR.*
```bash
python lpr_service.py \
  --input_dir "alpr_pipeline/output/2_lpqa_sorted/accepted" \
  --output_dir "alpr_pipeline/output/3_lpr_ocr" \
  --checkpoint "alpr_pipeline/models/lpr_model.ckpt"
```

**Terminal 4: Start the LPDBM Service**
*This service watches for OCR results and matches them against the database.*
```bash
python lpdbm_service.py \
  --watch_dir "alpr_pipeline/output/3_lpr_ocr" \
  --output_file "alpr_pipeline/output/4_lpdbm_matches/matches.log" \
  --db "alpr_pipeline/data/plates.db"
```

The pipeline is now running. As you add new images to `alpr_pipeline/data/raw_images`, they will be processed automatically through all stages. To stop the services, press `Ctrl+C` in each terminal.

### Post-Processing: Running the Analysis

After your image batch has been fully processed and you have stopped the services, run the final analysis script to categorize the accuracy of the results.

**Terminal 5: Run the Analysis Service**
```bash
python analysis.py \
  --input_file "alpr_pipeline/output/4_lpdbm_matches/matches.log" \
  --output_dir "alpr_pipeline/output/5_analysis_results"
```
The results will be neatly organized into files within the `5_analysis_results` directory, giving you a clear summary of the pipeline's performance.